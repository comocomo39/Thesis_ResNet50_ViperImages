{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzS3NdIBDb4N"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "########################Parte di codice commentata utilizzata per generare i dati di latitudine e longitudine normalizzati\n",
        "\n",
        "with open(\"/home/studente1/Downloads/aspis_out.csv\",'r') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    total0_lat=0\n",
        "    total0_lon=0\n",
        "    count0=0\n",
        "    for row in reader:\n",
        "        total0_lat+= float(row['latitude'])\n",
        "        total0_lon+= float(row['longitude'])\n",
        "        count0+=1\n",
        "    file.seek(0)\n",
        "    next(reader)\n",
        "    mean0_lat = total0_lat / count0\n",
        "    mean0_lon = total0_lon / count0\n",
        "    variance_lat0=0\n",
        "    variance_lon0 = 0\n",
        "    for row in reader:\n",
        "        value_lat0 = float(row['latitude'])\n",
        "        variance_lat0+=(value_lat0-mean0_lon) ** 2\n",
        "        value_lon0 = float(row['longitude'])\n",
        "        variance_lon0 += (value_lon0 - mean0_lon) ** 2\n",
        "    variance_lat0= variance_lat0 /(count0-1)\n",
        "    variance_lon0 = variance_lon0 / (count0 - 1)\n",
        "    std_dev_lat0 = math.sqrt(variance_lat0)\n",
        "    std_dev_lon0 = math.sqrt(variance_lon0)\n",
        "\n",
        "with open(\"/home/studente1/Downloads/aspis_out.csv\",'r') as file:\n",
        "    reader= csv.DictReader(file)\n",
        "    rows0=[]\n",
        "    for row in reader:\n",
        "        lat_value0 = float(row['latitude'])\n",
        "        lon_value0 = float(row['longitude'])\n",
        "        lat_z0 = (lat_value0 - mean0_lat) / std_dev_lat0\n",
        "        lon_z0 = (lon_value0 - mean0_lon) / std_dev_lon0\n",
        "        row['latitude-norm'] = lat_z0\n",
        "        row['longitude-norm'] = lon_z0\n",
        "        rows0.append(row)\n",
        "\n",
        "with open(\"/home/studente1/Downloads/aspis_out.csv\", 'w', newline='') as file:\n",
        "    fieldnames = reader.fieldnames + ['latitude-norm','longitude-norm']\n",
        "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for row in rows0:\n",
        "        writer.writerow(row)\n",
        "\n",
        "with open(\"/home/studente1/Downloads/berus_out.csv\", 'r') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    total1_lat = 0\n",
        "    total1_lon = 0\n",
        "    count1 = 0\n",
        "    for row in reader:\n",
        "        total1_lat += float(row['latitude'])\n",
        "        total1_lon += float(row['longitude'])\n",
        "        count1 += 1\n",
        "    file.seek(0)\n",
        "    next(reader)\n",
        "    mean1_lat = total1_lat / count1\n",
        "    mean1_lon = total1_lon / count1\n",
        "    variance_lat=0\n",
        "    variance_lon = 0\n",
        "    for row in reader:\n",
        "        value_lat = float(row['latitude'])\n",
        "        variance_lat+=(value_lat-mean1_lon) ** 2\n",
        "        value_lon = float(row['longitude'])\n",
        "        variance_lon += (value_lon - mean1_lon) ** 2\n",
        "    variance_lat= variance_lat /(count1-1)\n",
        "    variance_lon = variance_lon / (count1 - 1)\n",
        "    std_dev_lat1 = math.sqrt(variance_lat)\n",
        "    std_dev_lon1 = math.sqrt(variance_lon)\n",
        "\n",
        "with open(\"/home/studente1/Downloads/berus_out.csv\",'r') as file:\n",
        "    reader= csv.DictReader(file)\n",
        "    rows1=[]\n",
        "    for row in reader:\n",
        "        lat_value = float(row['latitude'])\n",
        "        lon_value = float(row['longitude'])\n",
        "        lat_z = (lat_value - mean1_lat) / std_dev_lat1\n",
        "        lon_z = (lon_value - mean1_lon) / std_dev_lon1\n",
        "        row['latitude-norm'] = lat_z\n",
        "        row['longitude-norm'] = lon_z\n",
        "        rows1.append(row)\n",
        "\n",
        "with open(\"/home/studente1/Downloads/berus_out.csv\", 'w', newline='') as file:\n",
        "    fieldnames = reader.fieldnames + ['latitude-norm','longitude-norm']\n",
        "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for row in rows1:\n",
        "        writer.writerow(row)\n",
        "\n",
        "########################\n",
        "\n",
        "# Carica i dati della prima classe dal primo file CSV\n",
        "class1_data = pd.read_csv(\"/home/studente1/Downloads/aspis_out.csv\")\n",
        "class1_data['label'] = 0\n",
        "\n",
        "# Carica i dati della seconda classe dal secondo file CSV\n",
        "#Forse pu√≤ creare problemi il fatto che\n",
        "# i due dataset siano di grandezze molto differenti (2000vs6000)\n",
        "class2_data = pd.read_csv(\"/home/studente1/Downloads/berus_out.csv\")\n",
        "class2_data['label'] = 1\n",
        "\n",
        "# Unisci i dati delle due classi in un unico DataFrame\n",
        "data = pd.concat([class1_data, class2_data], ignore_index=True)\n",
        "\n",
        "# Seleziona le colonne di interesse\n",
        "X = data[['latitude-norm', 'longitude-norm']]\n",
        "y = data['label']\n",
        "\n",
        "# Effettua lo split dei dati in set di training e di testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#print(len(X_train))\n",
        "#print(len(y_train))\n",
        "#print(len(X_test))\n",
        "#print(len(y_test))\n",
        "#print(X_train)\n",
        "#print(y_train)\n",
        "#print(X_test)\n",
        "#print(y_test)\n",
        "# Addestra un modello di classificazione sui dati di training\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Valuta il modello sui dati di testing\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy LogisticRegression:\", roc_auc_score(y_test,model.predict(X_test)))\n",
        "\n",
        "#Addestro il modello e lo valuto con la curva di roc\n",
        "clf= svm.SVC(kernel='linear')\n",
        "clf.fit(X_train,y_train)\n",
        "print(\"Accuracy SVM linear:\", roc_auc_score(y_test,clf.predict(X_test)))\n",
        "\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "#fig = px.scatter_geo(data,lat=\"latitude\",lon=\"longitude\",color='label',color_discrete_map={\"0\":\"blue\", \"1\":\"yellow\"})\n",
        "#fig.update_layout(title = 'dataset vipera aspis e berus', title_x=0.5)# legend_title=\"Legenda\", showlegend=True)\n",
        "#fig.show()\n"
      ]
    }
  ]
}